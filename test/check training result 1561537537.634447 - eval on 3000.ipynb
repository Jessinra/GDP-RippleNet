{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <b><i> Test RippleNet Result </b></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# > Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "from ipywidgets import FloatProgress, IntProgress\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# > Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEST_CODE = \"1561537537.634447\"\n",
    "CHOSEN_EPOCH = 8\n",
    "\n",
    "MODEL_PATH = \"../log/{}/models/epoch_{}\".format(TEST_CODE, CHOSEN_EPOCH)\n",
    "LOG_PATH = \"../log/{}/log.txt\".format(TEST_CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# > Model src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Limit GPU usage\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Logger.py\n",
    "\n",
    "class Logger:\n",
    "\n",
    "    def set_default_filename(self, filename):\n",
    "        self.default_filename = filename\n",
    "\n",
    "    def create_session_folder(self, path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError:\n",
    "            print(\"Creation of the directory %s failed\" % path)\n",
    "        else:\n",
    "            print(\"\\n ===> Successfully created the directory %s \\n\" % path)\n",
    "\n",
    "    def log(self, text):\n",
    "        with open(self.default_filename, 'a') as f:\n",
    "            f.writelines(text)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    def save_model(self, model, filename):\n",
    "        pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Model.py\n",
    "\n",
    "class RippleNet(object):\n",
    "\n",
    "    def __init__(self, args, n_entity, n_relation):\n",
    "\n",
    "        self._parse_args(args, n_entity, n_relation)\n",
    "        self._build_inputs()\n",
    "        self._build_embeddings()\n",
    "        self._build_model()\n",
    "        self._build_loss()\n",
    "        self._build_train()\n",
    "\n",
    "    def _parse_args(self, args, n_entity, n_relation):\n",
    "\n",
    "        self.n_entity = n_entity\n",
    "        self.n_relation = n_relation\n",
    "        self.dim = args.dim\n",
    "        self.n_hop = args.n_hop\n",
    "        self.kge_weight = args.kge_weight\n",
    "        self.l2_weight = args.l2_weight\n",
    "        self.lr = args.lr\n",
    "        self.n_memory = args.n_memory\n",
    "        self.item_update_mode = args.item_update_mode\n",
    "        self.using_all_hops = args.using_all_hops\n",
    "\n",
    "    def _build_inputs(self):\n",
    "\n",
    "        self.items = tf.placeholder(dtype=tf.int32, shape=[None], name=\"items\")\n",
    "        self.labels = tf.placeholder(dtype=tf.float64, shape=[None], name=\"labels\")\n",
    "        self.memories_h = []\n",
    "        self.memories_r = []\n",
    "        self.memories_t = []\n",
    "\n",
    "        for hop in range(self.n_hop):\n",
    "\n",
    "            self.memories_h.append(\n",
    "                tf.placeholder(dtype=tf.int32, shape=[None, self.n_memory], name=\"memories_h_\" + str(hop)))\n",
    "\n",
    "            self.memories_r.append(\n",
    "                tf.placeholder(dtype=tf.int32, shape=[None, self.n_memory], name=\"memories_r_\" + str(hop)))\n",
    "\n",
    "            self.memories_t.append(\n",
    "                tf.placeholder(dtype=tf.int32, shape=[None, self.n_memory], name=\"memories_t_\" + str(hop)))\n",
    "\n",
    "    def _build_embeddings(self):\n",
    "\n",
    "        self.entity_emb_matrix = tf.get_variable(name=\"entity_emb_matrix\", dtype=tf.float64,\n",
    "                                                 shape=[self.n_entity, self.dim],\n",
    "                                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        self.relation_emb_matrix = tf.get_variable(name=\"relation_emb_matrix\", dtype=tf.float64,\n",
    "                                                   shape=[self.n_relation, self.dim, self.dim],\n",
    "                                                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    def _build_model(self):\n",
    "        # transformation matrix for updating item embeddings at the end of each hop\n",
    "        self.transform_matrix = tf.get_variable(name=\"transform_matrix\", shape=[self.dim, self.dim], dtype=tf.float64,\n",
    "                                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        # [batch size, dim]\n",
    "        self.item_embeddings = tf.nn.embedding_lookup(self.entity_emb_matrix, self.items)\n",
    "\n",
    "        self.h_emb_list = []\n",
    "        self.r_emb_list = []\n",
    "        self.t_emb_list = []\n",
    "\n",
    "        for i in range(self.n_hop):\n",
    "\n",
    "            # [batch size, n_memory, dim]\n",
    "            self.h_emb_list.append(tf.nn.embedding_lookup(self.entity_emb_matrix, self.memories_h[i]))\n",
    "\n",
    "            # [batch size, n_memory, dim, dim]\n",
    "            self.r_emb_list.append(tf.nn.embedding_lookup(self.relation_emb_matrix, self.memories_r[i]))\n",
    "\n",
    "            # [batch size, n_memory, dim]\n",
    "            self.t_emb_list.append(tf.nn.embedding_lookup(self.entity_emb_matrix, self.memories_t[i]))\n",
    "\n",
    "        o_list = self._key_addressing()\n",
    "\n",
    "        self.scores = tf.squeeze(self.predict(self.item_embeddings, o_list))\n",
    "        self.scores_normalized = tf.sigmoid(self.scores)\n",
    "\n",
    "    def _key_addressing(self):\n",
    "\n",
    "        o_list = []\n",
    "        for hop in range(self.n_hop):\n",
    "\n",
    "            # [batch_size, n_memory, dim, 1]\n",
    "            h_expanded = tf.expand_dims(self.h_emb_list[hop], axis=3)\n",
    "\n",
    "            # [batch_size, n_memory, dim]\n",
    "            Rh = tf.squeeze(tf.matmul(self.r_emb_list[hop], h_expanded), axis=3)\n",
    "\n",
    "            # [batch_size, dim, 1]\n",
    "            v = tf.expand_dims(self.item_embeddings, axis=2)\n",
    "\n",
    "            # [batch_size, n_memory]\n",
    "            probs = tf.squeeze(tf.matmul(Rh, v), axis=2)\n",
    "\n",
    "            # [batch_size, n_memory]\n",
    "            probs_normalized = tf.nn.softmax(probs)\n",
    "\n",
    "            # [batch_size, n_memory, 1]\n",
    "            probs_expanded = tf.expand_dims(probs_normalized, axis=2)\n",
    "\n",
    "            # [batch_size, dim]\n",
    "            o = tf.reduce_sum(self.t_emb_list[hop] * probs_expanded, axis=1)\n",
    "\n",
    "            self.item_embeddings = self.update_item_embedding(self.item_embeddings, o)\n",
    "            o_list.append(o)\n",
    "\n",
    "        return o_list\n",
    "\n",
    "    def update_item_embedding(self, item_embeddings, o):\n",
    "\n",
    "        if self.item_update_mode == \"replace\":\n",
    "            item_embeddings = o\n",
    "        elif self.item_update_mode == \"plus\":\n",
    "            item_embeddings = item_embeddings + o\n",
    "        elif self.item_update_mode == \"replace_transform\":\n",
    "            item_embeddings = tf.matmul(o, self.transform_matrix)\n",
    "        elif self.item_update_mode == \"plus_transform\":\n",
    "            item_embeddings = tf.matmul(item_embeddings + o, self.transform_matrix)\n",
    "        else:\n",
    "            raise Exception(\"Unknown item updating mode: \" + self.item_update_mode)\n",
    "\n",
    "        return item_embeddings\n",
    "\n",
    "    def predict(self, item_embeddings, o_list):\n",
    "\n",
    "        y = o_list[-1]\n",
    "        if self.using_all_hops:\n",
    "            for i in range(self.n_hop - 1):\n",
    "                y += o_list[i]\n",
    "\n",
    "        scores = tf.reduce_sum(item_embeddings * y, axis=1)\n",
    "        return scores\n",
    "\n",
    "    def _build_loss(self):\n",
    "\n",
    "        self.base_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=self.labels, logits=self.scores))\n",
    "\n",
    "        self.kge_loss = 0\n",
    "        for hop in range(self.n_hop):\n",
    "\n",
    "            h_expanded = tf.expand_dims(self.h_emb_list[hop], axis=2)\n",
    "            t_expanded = tf.expand_dims(self.t_emb_list[hop], axis=3)\n",
    "            hRt = tf.squeeze(tf.matmul(tf.matmul(h_expanded, self.r_emb_list[hop]), t_expanded))\n",
    "            self.kge_loss += tf.reduce_mean(tf.sigmoid(hRt))\n",
    "\n",
    "        self.kge_loss = -self.kge_weight * self.kge_loss\n",
    "\n",
    "        self.l2_loss = 0\n",
    "        for hop in range(self.n_hop):\n",
    "\n",
    "            self.l2_loss += tf.reduce_mean(tf.reduce_sum(self.h_emb_list[hop] * self.h_emb_list[hop]))\n",
    "            self.l2_loss += tf.reduce_mean(tf.reduce_sum(self.t_emb_list[hop] * self.t_emb_list[hop]))\n",
    "            self.l2_loss += tf.reduce_mean(tf.reduce_sum(self.r_emb_list[hop] * self.r_emb_list[hop]))\n",
    "            if self.item_update_mode == \"replace nonlinear\" or self.item_update_mode == \"plus nonlinear\":\n",
    "                self.l2_loss += tf.nn.l2_loss(self.transform_matrix)\n",
    "\n",
    "        self.l2_loss = self.l2_weight * self.l2_loss\n",
    "\n",
    "        self.loss = self.base_loss + self.kge_loss + self.l2_loss\n",
    "\n",
    "    def _build_train(self):\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "        '''\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        gradients, variables = zip(*optimizer.compute_gradients(self.loss))\n",
    "        gradients = [None if gradient is None else tf.clip_by_norm(gradient, clip_norm=5)\n",
    "                     for gradient in gradients]\n",
    "        self.optimizer = optimizer.apply_gradients(zip(gradients, variables))\n",
    "        '''\n",
    "\n",
    "    def train(self, sess, feed_dict):\n",
    "        return sess.run([self.optimizer, self.loss], feed_dict)\n",
    "\n",
    "    def eval(self, sess, feed_dict):\n",
    "\n",
    "        labels, scores = sess.run([self.labels, self.scores_normalized], feed_dict)\n",
    "\n",
    "        auc = roc_auc_score(y_true=labels, y_score=scores)\n",
    "\n",
    "        predictions = [1 if i >= 0.5 else 0 for i in scores]\n",
    "        acc = np.mean(np.equal(predictions, labels))\n",
    "\n",
    "        return auc, acc\n",
    "\n",
    "    # ============ Custom test purpose ============\n",
    "    def custom_eval(self, sess, feed_dict):\n",
    "\n",
    "        labels, scores = sess.run([self.labels, self.scores_normalized], feed_dict)\n",
    "        auc = roc_auc_score(y_true=labels, y_score=scores)\n",
    "        predictions = [1 if i >= 0.5 else 0 for i in scores]\n",
    "        acc = np.mean(np.equal(predictions, labels))\n",
    "\n",
    "        return auc, acc, labels, scores, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataloader.py\n",
    "\n",
    "def load_data(args):\n",
    "\n",
    "    train_data, eval_data, test_data, user_history_dict = _load_rating(args)\n",
    "    n_entity, n_relation, kg = load_kg(args)\n",
    "    ripple_set = _get_ripple_set(args, kg, user_history_dict)\n",
    "\n",
    "    return train_data, eval_data, test_data, n_entity, n_relation, ripple_set\n",
    "\n",
    "\n",
    "def _load_rating(args):\n",
    "    print('reading rating file ...')\n",
    "\n",
    "    rating_file = '../data/' + args.dataset + '/ratings_final'\n",
    "\n",
    "    if os.path.exists(rating_file + '.npy'):\n",
    "        print(\"loaded from cache : {}.npy\".format(rating_file))\n",
    "        rating_np = np.load(rating_file + '.npy')\n",
    "\n",
    "    else:\n",
    "        rating_np = np.loadtxt(rating_file + '.txt', dtype=np.int32)\n",
    "\n",
    "        print(\"saved to cache : {}.npy\".format(rating_file))\n",
    "        np.save(rating_file + '.npy', rating_np)\n",
    "\n",
    "    return _dataset_split(rating_np, eval_ratio=args.eval_ratio, test_ratio=args.test_ratio)\n",
    "\n",
    "\n",
    "def _dataset_split(rating_np, eval_ratio=0.2, test_ratio=0.2):\n",
    "    print('splitting dataset ...')\n",
    "\n",
    "    n_ratings = rating_np.shape[0]\n",
    "\n",
    "    eval_indices = np.random.choice(n_ratings, size=int(n_ratings * eval_ratio), replace=False)\n",
    "    left = set(range(n_ratings)) - set(eval_indices)\n",
    "\n",
    "    test_indices = np.random.choice(list(left), size=int(n_ratings * test_ratio), replace=False)\n",
    "    train_indices = list(left - set(test_indices))\n",
    "\n",
    "    # traverse training data, only keeping the users with positive ratings\n",
    "    user_history_dict = dict()\n",
    "    for i in train_indices:\n",
    "        user = rating_np[i][0]\n",
    "        item = rating_np[i][1]\n",
    "        rating = rating_np[i][2]\n",
    "        if rating == 1:\n",
    "            if user not in user_history_dict:\n",
    "                user_history_dict[user] = []\n",
    "            user_history_dict[user].append(item)\n",
    "\n",
    "    train_indices = [i for i in train_indices if rating_np[i][0] in user_history_dict]\n",
    "    eval_indices = [i for i in eval_indices if rating_np[i][0] in user_history_dict]\n",
    "    test_indices = [i for i in test_indices if rating_np[i][0] in user_history_dict]\n",
    "\n",
    "    train_data = rating_np[train_indices]\n",
    "    eval_data = rating_np[eval_indices]\n",
    "    test_data = rating_np[test_indices]\n",
    "\n",
    "    return train_data, eval_data, test_data, user_history_dict\n",
    "\n",
    "\n",
    "def load_kg(args):\n",
    "    print('reading KG file ...')\n",
    "\n",
    "    kg_file = '../data/' + args.dataset + '/kg_final'\n",
    "\n",
    "    if os.path.exists(kg_file + '.npy'):\n",
    "        print(\"loaded from cache : {}.npy\".format(kg_file))\n",
    "        kg_numpy = np.load(kg_file + '.npy')\n",
    "\n",
    "    else:\n",
    "        kg_numpy = np.loadtxt(kg_file + '.txt', dtype=np.int32)\n",
    "\n",
    "        print(\"saved to cache : {}.npy\".format(kg_file))\n",
    "        np.save(kg_file + '.npy', kg_numpy)\n",
    "\n",
    "    n_entity = len(set(kg_numpy[:, 0]) | set(kg_numpy[:, 2]))\n",
    "    n_relation = len(set(kg_numpy[:, 1]))\n",
    "\n",
    "    kg = _construct_kg(kg_numpy)\n",
    "\n",
    "    return n_entity, n_relation, kg\n",
    "\n",
    "\n",
    "def _construct_kg(kg_numpy):\n",
    "    print('constructing knowledge graph ...')\n",
    "\n",
    "    kg = collections.defaultdict(list)\n",
    "    for head, relation, tail in kg_numpy:\n",
    "        kg[head].append((tail, relation))\n",
    "\n",
    "    return kg\n",
    "\n",
    "\n",
    "def _get_ripple_set(args, kg, user_history_dict):\n",
    "    print('constructing ripple set ...')\n",
    "\n",
    "    # Creating dictionary with format :\n",
    "    # {user : [(hop_0_heads, hop_0_relations, hop_0_tails), (hop_1_heads, hop_1_relations, hop_1_tails), ...]}\n",
    "\n",
    "    ripple_set = collections.defaultdict(list)\n",
    "    for user in tqdm(user_history_dict):\n",
    "        for h in range(args.n_hop):\n",
    "            memories_h = []\n",
    "            memories_r = []\n",
    "            memories_t = []\n",
    "\n",
    "            if h == 0:\n",
    "                tails_of_last_hop = user_history_dict[user]\n",
    "            else:\n",
    "                tails_of_last_hop = ripple_set[user][-1][2]\n",
    "\n",
    "            for entity in tails_of_last_hop:\n",
    "                for tail_and_relation in kg[entity]:\n",
    "                    memories_h.append(entity)\n",
    "                    memories_r.append(tail_and_relation[1])\n",
    "                    memories_t.append(tail_and_relation[0])\n",
    "\n",
    "            # if the current ripple set of the given user is empty, we simply copy the ripple set of the last hop here\n",
    "            # this won't happen for h = 0, because only the items that appear in the KG have been selected\n",
    "            # this only happens on 154 users in Book-Crossing dataset (since both BX dataset and the KG are sparse)\n",
    "            if len(memories_h) == 0:\n",
    "                ripple_set[user].append(ripple_set[user][-1])\n",
    "\n",
    "            else:\n",
    "                # sample a fixed-size 1-hop memory for each user\n",
    "                replace = len(memories_h) < args.n_memory\n",
    "                indices = np.random.choice(len(memories_h), size=args.n_memory, replace=replace)\n",
    "\n",
    "                memories_h = [memories_h[i] for i in indices]\n",
    "                memories_r = [memories_r[i] for i in indices]\n",
    "                memories_t = [memories_t[i] for i in indices]\n",
    "\n",
    "                ripple_set[user].append((memories_h, memories_r, memories_t))\n",
    "\n",
    "    return ripple_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train.py\n",
    "\n",
    "timestamp = str(datetime.timestamp(datetime.now()))\n",
    "SESSION_LOG_PATH = \"../log/{}/\".format(timestamp)\n",
    "\n",
    "def train(args, data_info, show_loss, config):\n",
    "\n",
    "    train_data = data_info[0]\n",
    "    eval_data = data_info[1]\n",
    "    test_data = data_info[2]\n",
    "    n_entity = data_info[3]\n",
    "    n_relation = data_info[4]\n",
    "    ripple_set = data_info[5]\n",
    "\n",
    "    logger = Logger()\n",
    "    logger.create_session_folder(SESSION_LOG_PATH)\n",
    "    logger.set_default_filename(SESSION_LOG_PATH + \"log.txt\")\n",
    "    logger.log(str(args))   # Log training and model hyper parameters\n",
    "\n",
    "    model = RippleNet(args, n_entity, n_relation)\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "        for step in range(args.n_epoch):\n",
    "\n",
    "            np.random.shuffle(train_data)\n",
    "\n",
    "            # training\n",
    "            for i in tqdm(range(0, train_data.shape[0], args.batch_size)):\n",
    "\n",
    "                _, loss = model.train(sess, _get_feed_dict(args, model, train_data, ripple_set, i, i + args.batch_size))\n",
    "\n",
    "                if show_loss:\n",
    "                    print('%.1f%% %.4f' % (i / train_data.shape[0] * 100, loss))\n",
    "                    logger.log('%.1f%% %.4f' % (i / train_data.shape[0] * 100, loss))\n",
    "\n",
    "            # evaluation\n",
    "            train_auc, train_acc = _evaluation(sess, args, model, train_data, ripple_set)\n",
    "            eval_auc, eval_acc = _evaluation(sess, args, model, eval_data, ripple_set)\n",
    "            test_auc, test_acc = _evaluation(sess, args, model, test_data, ripple_set)\n",
    "\n",
    "            # Save the variables to disk.\n",
    "            saver.save(sess, SESSION_LOG_PATH + \"models/epoch_{}\".format(step))\n",
    "\n",
    "            print('epoch %d    train auc: %.4f  acc: %.4f    eval auc: %.4f  acc: %.4f    test auc: %.4f  acc: %.4f'\n",
    "                  % (step, train_auc, train_acc, eval_auc, eval_acc, test_auc, test_acc))\n",
    "\n",
    "            logger.log(\n",
    "                'epoch %d    train auc: %.4f  acc: %.4f    eval auc: %.4f  acc: %.4f    test auc: %.4f  acc: %.4f'\n",
    "                % (step, train_auc, train_acc, eval_auc, eval_acc, test_auc, test_acc))\n",
    "\n",
    "\n",
    "def _get_feed_dict(args, model, data, ripple_set, start, end):\n",
    "\n",
    "    feed_dict = dict()\n",
    "    feed_dict[model.items] = data[start:end, 1]\n",
    "    feed_dict[model.labels] = data[start:end, 2]\n",
    "\n",
    "    for i in range(args.n_hop):\n",
    "        feed_dict[model.memories_h[i]] = [ripple_set[user][i][0] for user in data[start:end, 0]]\n",
    "        feed_dict[model.memories_r[i]] = [ripple_set[user][i][1] for user in data[start:end, 0]]\n",
    "        feed_dict[model.memories_t[i]] = [ripple_set[user][i][2] for user in data[start:end, 0]]\n",
    "\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def _evaluation(sess, args, model, eval_data, ripple_set):\n",
    "\n",
    "    auc_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    for i in tqdm(range(0, eval_data.shape[0], args.batch_size)):\n",
    "        auc, acc = model.eval(sess, _get_feed_dict(args, model, eval_data, ripple_set, i, i + args.batch_size))\n",
    "        auc_list.append(auc)\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    return float(np.mean(auc_list)), float(np.mean(acc_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# > Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataset = 'movie'\n",
    "        self.dim = 16\n",
    "        self.eval_ratio = 0.2\n",
    "        self.test_ratio = 0.2\n",
    "        self.n_hop = 2\n",
    "        self.kge_weight = 0.01\n",
    "        self.l2_weight = 1e-07\n",
    "        self.lr = 0.02\n",
    "        self.batch_size = 1024\n",
    "        self.n_epoch = 10\n",
    "        self.n_memory = 32\n",
    "        self.item_update_mode = 'plus_transform'\n",
    "        self.using_all_hops = True\n",
    "        self.comment = \"running normally\"\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## >> Load cache dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from cache : ../data/movie/preprocessed_data_info_32\n"
     ]
    }
   ],
   "source": [
    "# Main.py\n",
    "\n",
    "cached_preprocessed_data_filename = \"../data/movie/preprocessed_data_info_{}\".format(args.n_memory)\n",
    "\n",
    "# Preprocess data info\n",
    "if os.path.exists(cached_preprocessed_data_filename):\n",
    "    print(\"loaded from cache : {}\".format(cached_preprocessed_data_filename))\n",
    "    data_info = pickle.load(open(cached_preprocessed_data_filename, 'rb'))\n",
    "\n",
    "else:\n",
    "    data_info = load_data(args)\n",
    "\n",
    "    print(\"saved to cache : {}\".format(cached_preprocessed_data_filename))\n",
    "    pickle.dump(data_info, open(cached_preprocessed_data_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Separate the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_info[0]\n",
    "eval_data = data_info[1]\n",
    "test_data = data_info[2]\n",
    "n_entity = data_info[3]\n",
    "n_relation = data_info[4]\n",
    "ripple_set = data_info[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Create truth dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8235631/8235631 [00:27<00:00, 297633.76it/s]\n",
      "100%|██████████| 2744563/2744563 [00:11<00:00, 242148.74it/s]\n",
      "100%|██████████| 2744582/2744582 [00:11<00:00, 241458.77it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_truth_dict():\n",
    "\n",
    "    truth_dict = {}\n",
    "    for rating in tqdm(train_data):\n",
    "        user_id, movie_id, score = rating\n",
    "\n",
    "        if user_id not in truth_dict:\n",
    "            truth_dict[user_id] = []\n",
    "\n",
    "        if score == 1:\n",
    "            truth_dict[user_id].append(movie_id)\n",
    "\n",
    "    for rating in tqdm(test_data):\n",
    "        user_id, movie_id, score = rating\n",
    "\n",
    "        if user_id not in truth_dict:\n",
    "            truth_dict[user_id] = []\n",
    "\n",
    "        if score == 1:\n",
    "            truth_dict[user_id].append(movie_id)\n",
    "\n",
    "    for rating in tqdm(eval_data):\n",
    "        user_id, movie_id, score = rating\n",
    "\n",
    "        if user_id not in truth_dict:\n",
    "            truth_dict[user_id] = []\n",
    "\n",
    "        if score == 1:\n",
    "            truth_dict[user_id].append(movie_id)\n",
    "\n",
    "    return truth_dict\n",
    "\n",
    "\n",
    "truth_dict = generate_truth_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## >> Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 12:22:31.180547 140527826364160 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0801 12:22:31.261180 140527826364160 deprecation.py:323] From /home/jessinra/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = RippleNet(args, n_entity, n_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 12:22:32.499041 140527826364160 deprecation.py:323] From /home/jessinra/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.import_meta_graph(MODEL_PATH + \".meta\")\n",
    "saver.restore(sess, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## >> Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, args, model, users, items):\n",
    "\n",
    "    test_data = _preprocess_test_data(users, items)\n",
    "\n",
    "    scores = []\n",
    "    for i in range(0, len(test_data), args.batch_size):\n",
    "\n",
    "        feed_dict = _get_feed_dict(args, model, test_data, ripple_set, i, i + args.batch_size)\n",
    "        _, _, _, batch_scores, _ = model.custom_eval(sess, feed_dict)\n",
    "        scores = np.concatenate((scores, batch_scores))\n",
    "\n",
    "    return scores\n",
    "\n",
    "def _preprocess_test_data(users, items):\n",
    "    \"Preprocess test data so ripplenet can do feed forward with the right format\"\n",
    "    \n",
    "    dummy_value = True\n",
    "\n",
    "    cust_test_data = []\n",
    "    for user in users:\n",
    "        for item in items:\n",
    "            cust_test_data.append([user, item, int(dummy_value)]) # The last dummy value to match input format\n",
    "            dummy_value = not(dummy_value)\n",
    "            \n",
    "    return np.array(cust_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestion(user, k):\n",
    "\n",
    "    items = [i for i in range(0, 15440)]\n",
    "    prediction = predict(sess, args, model, [user], items)\n",
    "    score_item_pairs = [(prediction[i], i) for i in items]\n",
    "    top_k_recommendations = sorted(score_item_pairs, reverse=True)[:k]\n",
    "\n",
    "    return top_k_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_truth(user, k):\n",
    "    return truth_dict[user] if user in truth_dict else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_precision(prediction, truth, k=10):\n",
    "    intersect = _get_intersect_pred_truth(prediction, truth, k)\n",
    "    len_intersect = len(intersect)\n",
    "    len_truth = len(truth) if 0 < len(truth) <= k else k\n",
    "\n",
    "    return intersect, len_intersect / len_truth\n",
    "\n",
    "def _get_intersect_pred_truth(pred, truth, k):\n",
    "    pred_item_set = {x[1] for x in pred}\n",
    "    truth_item_set = set(truth)\n",
    "\n",
    "    return pred_item_set.intersection(truth_item_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 271/3000 [03:26<55:54,  1.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 1079 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 328/3000 [04:18<40:45,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 1723 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 461/3000 [06:17<34:23,  1.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 5267 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 600/3000 [08:15<29:11,  1.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 5905 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 625/3000 [08:31<27:39,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 8662 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1018/3000 [13:51<43:02,  1.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 1723 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1256/3000 [16:51<19:27,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 11655 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 1388/3000 [18:27<22:36,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 11556 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1464/3000 [19:19<16:42,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 2086 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1834/3000 [24:01<15:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 13862 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1944/3000 [25:34<20:42,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 6488 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1958/3000 [25:43<12:05,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 14539 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2021/3000 [26:28<12:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 12695 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2055/3000 [26:52<10:46,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 6251 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2155/3000 [28:07<12:40,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 12966 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2165/3000 [28:14<10:16,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 10703 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 2562/3000 [33:21<05:05,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 5905 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 2890/3000 [37:17<01:14,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 6488 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 2949/3000 [37:57<00:34,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 8662 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 2982/3000 [38:20<00:12,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occur for 3721 : list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [38:31<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "k_suggestion = 10\n",
    "n_users = 3000\n",
    "\n",
    "sample_user = np.random.randint(1, 15000, n_users) # sampling\n",
    "# sample_user = [i in range(0, 15000)] # uncomment to use non sampling\n",
    "\n",
    "suggested_items = []\n",
    "truth_items = []\n",
    "intersects = []\n",
    "scores = []\n",
    "\n",
    "all_intersect = None\n",
    "all_union = None\n",
    "\n",
    "for user in tqdm(sample_user):\n",
    "\n",
    "    try:\n",
    "\n",
    "        top_suggestions = get_suggestion(user, k_suggestion)\n",
    "        top_suggested_items = set([x[1] for x in top_suggestions])\n",
    "        top_truth_items = get_top_truth(user, k_suggestion)\n",
    "\n",
    "        intersect, score = check_precision(top_suggestions, top_truth_items, k=k_suggestion)\n",
    "\n",
    "        suggested_items.append(top_suggested_items)\n",
    "        truth_items.append(top_truth_items)\n",
    "        intersects.append(intersect)\n",
    "        scores.append(score)\n",
    "\n",
    "        if all_intersect is None:\n",
    "            all_intersect = top_suggested_items\n",
    "        else:\n",
    "            all_intersect = all_intersect.intersection(top_suggested_items)\n",
    "\n",
    "        if all_union is None:\n",
    "            all_union = top_suggested_items\n",
    "        else:\n",
    "            all_union = all_union.union(top_suggested_items)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error occur for {} : {}\".format(user, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec@k score: 0.2725561947374028\n",
      "\n",
      "intersect\n",
      "set() 0\n",
      "\n",
      "union\n",
      "{7170, 11268, 9224, 2057, 9226, 9227, 10252, 10, 20, 1048, 2073, 2074, 10268, 14364, 10272, 2084, 2085, 5161, 9257, 11309, 2093, 7219, 3124, 12341, 12342, 12339, 8252, 1085, 12351, 3137, 12354, 10306, 2114, 4165, 11334, 6215, 14408, 5185, 8266, 13386, 2124, 1101, 2125, 2130, 11347, 5203, 10328, 5209, 4195, 4196, 1125, 8293, 5230, 1138, 9331, 7285, 1142, 122, 125, 5246, 3200, 10369, 10371, 6276, 7304, 14472, 136, 141, 10382, 10381, 1168, 7313, 12436, 4248, 5276, 4262, 9383, 12456, 1190, 170, 12461, 6320, 7347, 9396, 6325, 8377, 4284, 1216, 3264, 2243, 14532, 12489, 14537, 8397, 10455, 6362, 5339, 11484, 13533, 8421, 11494, 8422, 14569, 3307, 11501, 12531, 7417, 7423, 12545, 4353, 11523, 14596, 8454, 9481, 5387, 8460, 5391, 7442, 4370, 8474, 10524, 5409, 2339, 1318, 6439, 1321, 1322, 11564, 1324, 5425, 11570, 6457, 5439, 9536, 14657, 11584, 7489, 6463, 6469, 10565, 9544, 3401, 11600, 1361, 13650, 340, 13652, 1371, 7516, 12637, 14685, 12639, 11617, 7526, 4457, 8554, 2410, 8560, 1392, 4472, 1402, 3450, 11642, 4475, 14719, 11648, 10624, 2434, 8579, 8583, 4487, 6546, 10644, 9620, 2455, 8600, 3482, 1435, 9630, 11679, 7586, 10659, 10660, 4520, 11690, 12715, 4526, 7598, 1459, 3508, 3515, 4541, 9662, 9661, 2500, 13766, 4551, 12743, 457, 2506, 8652, 6605, 4557, 7629, 4556, 2514, 2517, 477, 12766, 11743, 8672, 3551, 6623, 4583, 9704, 13799, 9706, 491, 11757, 8688, 4597, 2551, 6648, 4601, 5629, 10750, 11775, 12799, 11777, 14848, 3590, 8714, 3603, 533, 534, 1559, 9749, 8729, 7707, 5661, 9758, 8734, 9763, 1572, 2598, 11823, 13872, 7727, 7730, 12847, 11832, 12860, 1598, 6727, 14920, 2633, 14923, 9804, 9805, 9806, 4687, 8783, 13910, 600, 8793, 616, 1640, 5738, 12909, 13933, 7794, 5746, 9844, 8820, 629, 11895, 7804, 10878, 8833, 2691, 14980, 11912, 2700, 656, 6800, 11924, 13975, 3740, 6818, 5795, 676, 6819, 10918, 9896, 6825, 11944, 3752, 8878, 10927, 6834, 14003, 693, 2741, 4791, 14007, 5817, 2744, 7867, 700, 7868, 7870, 8896, 5826, 709, 7877, 710, 14025, 15049, 11979, 15053, 1741, 2767, 3794, 6873, 15073, 7907, 2790, 3815, 1772, 7917, 1773, 8943, 8946, 13043, 14066, 4854, 1782, 5880, 1785, 11002, 7927, 11006, 8962, 2818, 15110, 6918, 778, 2829, 14094, 3855, 10002, 1811, 3860, 6930, 5910, 2840, 3870, 2851, 2863, 6962, 15154, 5939, 12084, 3896, 832, 13122, 15171, 10055, 12107, 8012, 12113, 13140, 854, 10076, 12126, 12127, 5987, 3943, 8053, 886, 7036, 15231, 6018, 7042, 15237, 15238, 8074, 911, 2959, 7057, 1938, 15249, 14231, 9111, 9113, 2974, 6050, 7076, 8100, 15271, 11177, 7083, 11181, 13236, 11193, 7097, 15294, 4031, 5055, 3009, 5058, 9157, 965, 4044, 7120, 7124, 8148, 11224, 10201, 15323, 5086, 11233, 9185, 2032, 4080, 14320, 9206, 7162, 11263} 429\n",
      "\n",
      "distinct rate\n",
      "0.0143\n"
     ]
    }
   ],
   "source": [
    "print(\"Prec@k score:\", np.average(scores))\n",
    "# print(\"top_suggested_items:\", top_suggested_items)\n",
    "# print(\"truth_items:\", truth_items)\n",
    "\n",
    "print(\"\\nintersect\")\n",
    "print(all_intersect, len(all_intersect))\n",
    "print(\"\\nunion\")\n",
    "print(all_union, len(all_union))\n",
    "print(\"\\ndistinct rate\")\n",
    "print((len(all_union)) / (n_users * k_suggestion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0.9893943039592765, 14920),\n",
       " (0.9892559623468036, 3401),\n",
       " (0.9891971447498329, 2073),\n",
       " (0.9891202423296668, 491),\n",
       " (0.9883482345694753, 1125),\n",
       " (0.9878900161933994, 1321),\n",
       " (0.9863407447129022, 911),\n",
       " (0.9861109333842524, 10659),\n",
       " (0.9855997942194948, 6018),\n",
       " (0.9847622048340937, 5058)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[14920, 3401, 2073, 491, 1125, 1321, 911, 10659, 6018, 5058]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[11648,\n",
       " 9122,\n",
       " 10659,\n",
       " 3401,\n",
       " 2025,\n",
       " 7948,\n",
       " 911,\n",
       " 7794,\n",
       " 4687,\n",
       " 12081,\n",
       " 13872,\n",
       " 2073,\n",
       " 3777,\n",
       " 8074,\n",
       " 12197,\n",
       " 1630,\n",
       " 6032,\n",
       " 7631,\n",
       " 1125,\n",
       " 11536]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({911, 1125, 2073, 3401, 10659}, 0.5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'=================='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "95786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0.997074183012745, 2073),\n",
       " (0.9969471222003896, 7285),\n",
       " (0.9969064635458472, 491),\n",
       " (0.9966161261297234, 1321),\n",
       " (0.9964825140810721, 10002),\n",
       " (0.9962638273605738, 14920),\n",
       " (0.9959097599400564, 6825),\n",
       " (0.9952965202872629, 7304),\n",
       " (0.9950498534101515, 911),\n",
       " (0.9948882145262539, 3401)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2073, 7285, 491, 1321, 10002, 14920, 6825, 7304, 911, 3401]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[6036,\n",
       " 8860,\n",
       " 8609,\n",
       " 12451,\n",
       " 11564,\n",
       " 14025,\n",
       " 7885,\n",
       " 10833,\n",
       " 470,\n",
       " 5724,\n",
       " 7135,\n",
       " 14048,\n",
       " 3424,\n",
       " 15075,\n",
       " 2025,\n",
       " 3186,\n",
       " 2679,\n",
       " 5439,\n",
       " 1395,\n",
       " 14592,\n",
       " 12328,\n",
       " 5813,\n",
       " 9139,\n",
       " 4870]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(set(), 0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'=================='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "94772"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0.9984111972295332, 5738),\n",
       " (0.9983948576118624, 2073),\n",
       " (0.9982665294351841, 10659),\n",
       " (0.9980269475702577, 3401),\n",
       " (0.9980204860018823, 676),\n",
       " (0.997793777208644, 8688),\n",
       " (0.9976973312562193, 13122),\n",
       " (0.9975817257596806, 1321),\n",
       " (0.9975645198342102, 5058),\n",
       " (0.9975531794651232, 491)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[5738, 2073, 10659, 3401, 676, 8688, 13122, 1321, 5058, 491]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[5629,\n",
       " 13122,\n",
       " 11494,\n",
       " 7631,\n",
       " 11536,\n",
       " 2514,\n",
       " 2899,\n",
       " 4791,\n",
       " 2073,\n",
       " 7868,\n",
       " 1976,\n",
       " 14048,\n",
       " 9741,\n",
       " 6018,\n",
       " 14164,\n",
       " 11677,\n",
       " 7907,\n",
       " 7010]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({2073, 13122}, 0.2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'=================='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_user = [np.random.randint(1, 138000) for i in range(0, 3)]\n",
    "\n",
    "for user in sample_user:\n",
    "\n",
    "    prediction = get_suggestion(user, 10)\n",
    "    truth = get_top_truth(user, 10)\n",
    "\n",
    "    display(user)\n",
    "    display((prediction))\n",
    "    display([x[1] for x in prediction])\n",
    "    display((truth))\n",
    "    display(check_precision(prediction, truth, 10))\n",
    "    display(\"==================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
